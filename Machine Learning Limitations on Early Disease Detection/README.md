**Machine Learning Limitations on Early Disease Detection**

This repository presents a systematic experimental study demonstrating the limitations of classical machine learning approaches for early-stage plant disease detection, particularly under realistic, multi-class, and imbalanced data conditions.

The work is structured to proveâ€”through controlled experimentation rather than opinionâ€”that traditional machine learning pipelines relying on handcrafted features are insufficient for reliable early disease detection, motivating the transition toward modern deep learningâ€“based approaches.

ğŸ“Œ Project Motivation

Early detection of plant diseases is critical for:

agricultural productivity,

food security,

and economic sustainability.

While classical machine learning (ML) methods are widely used due to their low computational cost and ease of implementation, most prior studies:

rely on controlled datasets,

report aggregate accuracy only, and

fail to analyze class-level reliability.

This project addresses that gap by asking a focused research question:

Are classical machine learning models with handcrafted features adequate for early disease detection under realistic conditions?

ğŸ¯ Objectives

The primary objectives of this study are:

To evaluate classical ML models across datasets of increasing realism and complexity

To analyze feature vs model behavior rather than only final accuracy

To expose class-level failures hidden by aggregate metrics

To demonstrate why accuracy alone is misleading

To justify the need for deep learning, transfer learning, and explainable AI

ğŸ“‚ Dataset Design (Core Experimental Logic)

Three publicly available plant disease datasets were selected to represent three progressively challenging scenarios:

1ï¸âƒ£ Tomato Dataset â€” Realistic, Multi-Class

Large-scale dataset

10 disease classes

High visual similarity between diseases

Represents real-world complexity

ğŸ“Œ Purpose: Test scalability and fine-grained disease separation

2ï¸âƒ£ Potato Dataset â€” Imbalanced

3 classes (Early Blight, Late Blight, Healthy)

Severe class imbalance

Healthy class is the minority

ğŸ“Œ Purpose: Analyze how accuracy hides minority-class failure

3ï¸âƒ£ Chili Dataset â€” Controlled, Ideal Case

Binary classification (Healthy vs Unhealthy)

Balanced classes

Controlled acquisition conditions

ğŸ“Œ Purpose: Show how classical ML appears to work perfectly under ideal conditions

ğŸ§  Experimental Pipeline

All datasets follow a uniform pipeline to ensure fair comparison:

Image preprocessing

Handcrafted feature extraction

Classical machine learning classification

Robust evaluation using class-level metrics

ğŸ§© Feature Extraction

Three feature configurations were evaluated:

ğŸ”¹ Haralick Texture Features

Derived from Gray-Level Co-occurrence Matrix (GLCM)

Capture spatial texture relationships

Effective in structured and controlled settings

ğŸ”¹ Histogram of Oriented Gradients (HOG)

Captures edge and gradient orientation

Effective for shape-dominant patterns

ğŸ”¹ Haralick + HOG (Feature Fusion)

Combines texture and gradient information

Evaluated to test whether feature fusion resolves limitations

ğŸ¤– Machine Learning Models

The following classical ML models were evaluated:

Support Vector Machine (SVM)

Random Forest (RF)

K-Nearest Neighbors (KNN)

ğŸ“Œ Key design choice:

Models were intentionally kept classical to isolate feature representation limitations, not model capacity.

ğŸ“ Validation Strategy

Tomato dataset: Repeated cross-validation
â†’ Results reported as mean Â± standard deviation

Potato & Chili datasets: Fixed evaluation protocol
â†’ Single accuracy value reported (no SD available)

This difference is methodologically correct and explicitly acknowledged.

ğŸ“Š Evaluation Metrics

Beyond accuracy, this project emphasizes reliability-focused metrics:

Overall Accuracy (for high-level comparison)

Per-Class Recall (primary reliability metric)

Confusion Matrices (error structure analysis)

Learning Curves (data vs performance behavior)

ğŸ“Œ Why recall matters:

A model with high accuracy but low recall for diseased classes is unsafe for early detection.

ğŸ” Key Experimental Findings
âœ… Accuracy is Misleading

Chili dataset achieves 0.90â€“1.00 accuracy, even with simple models

Potato dataset achieves ~0.87â€“0.91 accuracy, despite near-zero recall for healthy class

Tomato dataset accuracy varies widely (~0.54â€“0.78) and masks class confusion

âŒ Feature Representation is the Bottleneck

Switching classifiers yields marginal improvements

Switching features changes performance more than switching models

Misclassified classes remain consistent across models

ğŸ“Œ Conclusion:

Classifier choice cannot compensate for weak feature representation

âš ï¸ Class-Level Failures are Systematic

Tomato dataset shows recall as low as 0.16â€“0.42 for certain disease classes

Potato healthy class recall drops to 0.03â€“0.11 under some configurations

Chili dataset achieves near-perfect recall, revealing its artificial simplicity

ğŸ§ª Results Visualization

All figures, plots, and heatmaps used in the conference paper are stored in:

Conference Paper Presentation


This includes:

Learning curves

Per-class recall heatmaps

Confusion matrices

Accuracy vs recall comparisons



ğŸ“Œ Final Conclusion

This study demonstrates that:

Classical ML models can appear effective under controlled conditions

They fail systematically under realistic complexity

Aggregate accuracy hides critical failure modes

Handcrafted features lack the representational capacity required for early disease detection

ğŸš€ Future Improvements

The limitations identified in this work motivate the adoption of modern approaches:

Deep Learning (CNNs) for hierarchical feature learning

Transfer Learning to leverage large-scale pretrained representations

Data Augmentation to mitigate class imbalance

Explainable AI (XAI) to ensure transparency and trust in predictions

These approaches are expected to address the representational bottlenecks exposed in this study.


ğŸ‘¤ Author

Mahin Khan
Data Science | Machine Learning | Applied Research
GitHub: Mahinkhan007
